{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e544bef9",
   "metadata": {},
   "source": [
    "# Drug Review Sentiment — Updated Pipeline\n",
    "Centralized outputs in `results/` and parameterized training via `src/train_model.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ac84112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/sandra/drug-review-sentiment\n",
      "MLflow tracking URI: file:///home/sandra/drug-review-sentiment/results/mlruns\n"
     ]
    }
   ],
   "source": [
    "# Optional: Colab setup — uncomment if running in Colab\n",
    "# %pip install -U transformers datasets peft scikit-learn mlflow accelerate evaluate matplotlib seaborn kagglehub\n",
    "\n",
    "import os, sys, pathlib, mlflow\n",
    "import tensorboard\n",
    "# Auto-detect repo root: if launched from notebooks/, go one level up\n",
    "cwd = pathlib.Path().resolve()\n",
    "repo_root = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "os.chdir(repo_root)\n",
    "sys.path.insert(0, str(repo_root))\n",
    "print('CWD:', os.getcwd())\n",
    "\n",
    "from src import logging_config as logcfg, config\n",
    "config.ensure_dirs()\n",
    "logcfg.setup_logger(config.TRAIN_LOG)\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Configure MLflow to track under results/mlruns via src.config\n",
    "mlflow.set_tracking_uri(config.mlflow_uri())\n",
    "print('MLflow tracking URI:', mlflow.get_tracking_uri())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e84aea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "CUDA available: False\n",
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "# 1. Mount Google Drive (for saving models/results)\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# 2. Clone your GitHub repo\n",
    "#git clone https://github.com/sandragodinhosilva/drug-review-sentiment\n",
    "#%cd drug-review-sentiment\n",
    "\n",
    "# 3. Install dependencies\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "# 4. Tensorboard\n",
    "%load_ext tensorboard\n",
    "# %tensorboard --logdir /content/drive/MyDrive/biobert_project/biobert_logs\n",
    "\n",
    "# 5. Verify GPU availability\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "# print(\"Current device:\", torch.cuda.current_device())\n",
    "# print(\"Tensor test:\", torch.rand(3,3).cuda())\n",
    "\n",
    "\n",
    "# 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f8291bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "models = {\n",
    "    \"distilbert-base-uncased\": {\n",
    "        \"model\": \"distilbert-base-uncased\",  # or 'dmis-lab/biobert-base-cased-v1.1'\n",
    "        \"subset_frac\": 0.005,  # use 0.0/None for full data\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 16,\n",
    "        \"fp16\": True,  # set False on CPU\n",
    "    },\n",
    "    \"biobert-base-cased-v1.1\": {\n",
    "        \"model\": \"dmis-lab/biobert-base-cased-v1.1\",\n",
    "        \"subset_frac\": 0.005,\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 16,\n",
    "        \"fp16\": True,  # set False on CPU\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f81e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND: data/drugsComTrain_raw.tsv (84.3 MB)\n",
      "FOUND: data/drugsComTest_raw.tsv (28.1 MB)\n",
      "drugsComTrain_raw.tsv columns: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount']\n",
      "drugsComTest_raw.tsv columns: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount']\n",
      "Preflight OK\n"
     ]
    }
   ],
   "source": [
    "# Preflight: check data files exist and have expected columns\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Expected filenames\n",
    "train_file = \"drugsComTrain_raw.tsv\"\n",
    "test_file = \"drugsComTest_raw.tsv\"\n",
    "\n",
    "# Local and Colab/Drive paths\n",
    "local_dir = Path(\"data\")\n",
    "drive_dir = Path(\"/content/drive/MyDrive/data\")  # Adjust if your Drive path differs\n",
    "local_train = local_dir / train_file\n",
    "local_test = local_dir / test_file\n",
    "drive_train = drive_dir / train_file\n",
    "drive_test = drive_dir / test_file\n",
    "\n",
    "local_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ensure_local(src: Path, dst: Path) -> bool:\n",
    "    if dst.exists():\n",
    "        sz = dst.stat().st_size / 1e6\n",
    "        print(f\"FOUND: {dst} ({sz:.1f} MB)\")\n",
    "        return True\n",
    "    if src.exists():\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src, dst)\n",
    "        sz = dst.stat().st_size / 1e6\n",
    "        print(f\"COPIED from {src} -> {dst} ({sz:.1f} MB)\")\n",
    "        return True\n",
    "    print(f\"MISSING: {dst}. Place the TSV in data/ or {src.parent}/\")\n",
    "    return False\n",
    "\n",
    "# Check training and test files\n",
    "ok_train = ensure_local(drive_train, local_train)\n",
    "ok_test = ensure_local(drive_test, local_test)\n",
    "ok = ok_train and ok_test\n",
    "\n",
    "# Quick schema check\n",
    "for pth in [local_train, local_test]:\n",
    "    if pth.exists():\n",
    "        try:\n",
    "            df = pd.read_csv(pth, sep=\"\\t\", nrows=5)\n",
    "            print(f\"{pth.name} columns:\", list(df.columns))\n",
    "            need = {\"review\", \"rating\"}\n",
    "            missing = need - set(df.columns)\n",
    "            if missing:\n",
    "                print(f\"WARNING: {pth.name} missing expected columns: {missing}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read sample from {pth}: {e}\")\n",
    "\n",
    "print(\"Preflight OK\" if ok else \"Preflight FAILED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9697ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training distilbert-base-uncased ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 19:11:47 - ipykernel_launcher - INFO - Loaded train=(161297, 7) from data/drugsComTrain_raw.tsv; test=(53766, 7) from data/drugsComTest_raw.tsv\n",
      "2025-09-14 19:11:48 - ipykernel_launcher - INFO - Label counts — train: {1: 113209, 0: 48088}; test: {1: 37559, 0: 16207}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m use_fp16 = cfg.get(\u001b[33m'\u001b[39m\u001b[33mfp16\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m=== Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimbalance_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweighted_loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fp16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tensorboard\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/drug-review-sentiment/src/train_model.py:109\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model_name, batch_size, num_train_epochs, imbalance_strategy, fp16, subset_frac, use_tensorboard)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(\n\u001b[32m    101\u001b[39m     model_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    102\u001b[39m     batch_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m16\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m     use_tensorboard: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    108\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     ds = \u001b[43mload_local_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_frac\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     logcfg.info(\u001b[33m\"\u001b[39m\u001b[33mDatasets loaded successfully.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m     model_id = _normalize_model_id(model_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/drug-review-sentiment/src/load_datasets.py:58\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(train_dir, test_dir, train_file, test_file, sep, sample_frac, random_state)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Clean review text and filter short/empty/duplicate rows\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m train[\u001b[33m\"\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mclean_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m test[\u001b[33m\"\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m\"\u001b[39m] = clean_series(test[\u001b[33m\"\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     61\u001b[39m train = filter_reviews(train, text_col=\u001b[33m\"\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m\"\u001b[39m, min_len=\u001b[32m5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/drug-review-sentiment/src/cleaning.py:89\u001b[39m, in \u001b[36mclean_series\u001b[39m\u001b[34m(series)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Vectorized cleaning for a pandas Series -> Not “vectorized” in the NumPy sense; \u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    its a simple, readable per-row apply that fits custom Python/regex logic.\u001b[39;00m\n\u001b[32m     80\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     86\u001b[39m \u001b[33;03m    Output: pd.Series([\"Great!\", \"\", \"Visit [URL]\"])\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# map runs clean_text element-by-element\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m result = \u001b[43mseries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     91\u001b[39m     _INFO(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclean_series: cleaned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(series)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m texts\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/drug-review-sentiment/.venv/lib/python3.12/site-packages/pandas/core/series.py:4711\u001b[39m, in \u001b[36mSeries.map\u001b[39m\u001b[34m(self, arg, na_action)\u001b[39m\n\u001b[32m   4631\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\n\u001b[32m   4632\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4633\u001b[39m     arg: Callable | Mapping | Series,\n\u001b[32m   4634\u001b[39m     na_action: Literal[\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4635\u001b[39m ) -> Series:\n\u001b[32m   4636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4637\u001b[39m \u001b[33;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[32m   4638\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4709\u001b[39m \u001b[33;03m    dtype: object\u001b[39;00m\n\u001b[32m   4710\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4711\u001b[39m     new_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4712\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor(new_values, index=\u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m).__finalize__(\n\u001b[32m   4713\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4714\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/drug-review-sentiment/.venv/lib/python3.12/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/drug-review-sentiment/.venv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/drug-review-sentiment/src/cleaning.py:73\u001b[39m, in \u001b[36mclean_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     71\u001b[39m text = _RE_CTRL.sub(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, text)\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# 6) Normalize whitespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m text = \u001b[43m_RE_WS\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m.strip()\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run training for each model in the dict\n",
    "from src.train_model import train_model\n",
    "for name, cfg in models.items():\n",
    "    m = cfg.get('model', name)\n",
    "    bs = cfg.get('batch_size', 16)\n",
    "    eps = cfg.get('epochs', 1)\n",
    "    subset = cfg.get('subset_frac', None)\n",
    "    use_fp16 = cfg.get('fp16', False)\n",
    "    print(f'=== Training {m} ===')\n",
    "    train_model(\n",
    "        model_name=m,\n",
    "        batch_size=bs,\n",
    "        num_train_epochs=eps,\n",
    "        imbalance_strategy='weighted_loss',\n",
    "        fp16=use_fp16,\n",
    "        subset_frac=subset,\n",
    "        use_tensorboard=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882cef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: a871100d092f49d887fbca4a0152e038  Name: distilbert-base-uncased-lora-128-weighted_loss\n",
      "{\n",
      "  \"test_eval_f1\": 0.8113695090439277,\n",
      "  \"test_eval_accuracy\": 0.6983471074380165,\n",
      "  \"test_eval_steps_per_second\": 0.913,\n",
      "  \"test_eval_runtime\": 8.7661,\n",
      "  \"test_eval_loss\": 0.6745060086250305,\n",
      "  \"test_eval_recall\": 0.9289940828402367,\n",
      "  \"test_eval_precision\": 0.7201834862385321,\n",
      "  \"test_eval_samples_per_second\": 27.606,\n",
      "  \"test_epoch\": 1.0\n",
      "}\n",
      "Run: 2e976997a8244ec5b4e998bc08d57ba9  Name: distilbert-base-uncased-lora-128-weighted_loss\n",
      "{\n",
      "  \"test_eval_f1\": 0.8113695090439277,\n",
      "  \"test_eval_accuracy\": 0.6983471074380165,\n",
      "  \"test_eval_steps_per_second\": 0.565,\n",
      "  \"test_eval_runtime\": 14.1579,\n",
      "  \"test_eval_loss\": 0.6745060086250305,\n",
      "  \"test_eval_recall\": 0.9289940828402367,\n",
      "  \"test_eval_precision\": 0.7201834862385321,\n",
      "  \"test_eval_samples_per_second\": 17.093,\n",
      "  \"test_epoch\": 1.0\n",
      "}\n",
      "Run: 12dcab98a908407eae2724292216703e  Name: distilbert-base-uncased-lora-128-weighted_loss\n",
      "{\n",
      "  \"test_eval_f1\": 0.8113695090439277,\n",
      "  \"test_eval_accuracy\": 0.6983471074380165,\n",
      "  \"test_eval_steps_per_second\": 0.809,\n",
      "  \"test_eval_runtime\": 9.8851,\n",
      "  \"test_eval_loss\": 0.6745060086250305,\n",
      "  \"test_eval_recall\": 0.9289940828402367,\n",
      "  \"test_eval_precision\": 0.7201834862385321,\n",
      "  \"test_eval_samples_per_second\": 24.481,\n",
      "  \"test_epoch\": 1.0\n",
      "}\n",
      "Run: 19480f2e08ff4011811d623a0759291b  Name: distilbert-base-uncased-lora-128-weighted_loss\n",
      "{\n",
      "  \"test_eval_f1\": 0.8312342569269522,\n",
      "  \"test_eval_accuracy\": 0.7231404958677686,\n",
      "  \"test_eval_steps_per_second\": 0.57,\n",
      "  \"test_eval_runtime\": 14.0324,\n",
      "  \"test_eval_loss\": 0.6635985374450684,\n",
      "  \"test_eval_recall\": 0.9763313609467456,\n",
      "  \"test_eval_precision\": 0.7236842105263158,\n",
      "  \"test_eval_samples_per_second\": 17.246,\n",
      "  \"test_epoch\": 1.0\n",
      "}\n",
      "Run: 255739eca4994d8f9c5e8bc0da3a0f8a  Name: distilbert-base-uncased-lora-128-weighted_loss\n",
      "{\n",
      "  \"test_eval_f1\": 0.8312342569269522,\n",
      "  \"test_eval_accuracy\": 0.7231404958677686,\n",
      "  \"test_eval_steps_per_second\": 0.8,\n",
      "  \"test_eval_runtime\": 9.994,\n",
      "  \"test_eval_loss\": 0.6635985374450684,\n",
      "  \"test_eval_recall\": 0.9763313609467456,\n",
      "  \"test_eval_precision\": 0.7236842105263158,\n",
      "  \"test_eval_samples_per_second\": 24.214,\n",
      "  \"test_epoch\": 1.0\n",
      "}\n",
      "Run: abdbafc2361e489981e41636a3ea3b1a  Name: distilbert-base-uncased-lora-128-weighted_loss\n",
      "{\n",
      "  \"test_eval_f1\": 0.8312342569269522,\n",
      "  \"test_eval_accuracy\": 0.7231404958677686,\n",
      "  \"test_eval_steps_per_second\": 0.655,\n",
      "  \"test_eval_runtime\": 12.2182,\n",
      "  \"test_eval_loss\": 0.6635985374450684,\n",
      "  \"test_eval_recall\": 0.9763313609467456,\n",
      "  \"test_eval_precision\": 0.7236842105263158,\n",
      "  \"test_eval_samples_per_second\": 19.807,\n",
      "  \"test_epoch\": 1.0\n",
      "}\n",
      "Run: 7c40f803f5ad446cb36321523e103ccd  Name: biobert-base-cased-v1.1-lora-128-weighted_loss\n",
      "{\n",
      "  \"test_eval_f1\": 0.05649717514124294,\n",
      "  \"test_eval_accuracy\": 0.30991735537190085,\n",
      "  \"test_eval_steps_per_second\": 0.288,\n",
      "  \"test_eval_runtime\": 27.7467,\n",
      "  \"test_eval_loss\": 0.7092041969299316,\n",
      "  \"test_eval_recall\": 0.029585798816568046,\n",
      "  \"test_eval_precision\": 0.625,\n",
      "  \"test_eval_samples_per_second\": 8.722,\n",
      "  \"test_epoch\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Compare latest runs (by run dir mtime) and show test metrics per run\n",
    "import glob, os, json\n",
    "runs = sorted(glob.glob('results/mlruns/*/*'), key=os.path.getmtime)[-10:]\n",
    "summary = []\n",
    "for rd in runs:\n",
    "    test_metrics = {}\n",
    "    for f in glob.glob(f'{rd}/metrics/test_*'):\n",
    "        with open(f) as fh:\n",
    "            t, v, step = fh.read().strip().split()\n",
    "            test_metrics[os.path.basename(f)] = float(v)\n",
    "    if test_metrics:\n",
    "        run_name=None\n",
    "        tag = os.path.join(rd, 'tags', 'mlflow.runName')\n",
    "        if os.path.exists(tag):\n",
    "            run_name = open(tag).read().strip()\n",
    "        summary.append((os.path.basename(rd), run_name, test_metrics))\n",
    "\n",
    "for run_id, run_name, tm in summary:\n",
    "    print(f'Run: {run_id}  Name: {run_name}')\n",
    "    print(json.dumps(tm, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8abe4f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_56b81_row0_col6, #T_56b81_row1_col6, #T_56b81_row2_col6 {\n",
       "  background-color: #d1ffd1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_56b81\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56b81_level0_col0\" class=\"col_heading level0 col0\" >run_id</th>\n",
       "      <th id=\"T_56b81_level0_col1\" class=\"col_heading level0 col1\" >run_name</th>\n",
       "      <th id=\"T_56b81_level0_col2\" class=\"col_heading level0 col2\" >model</th>\n",
       "      <th id=\"T_56b81_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "      <th id=\"T_56b81_level0_col4\" class=\"col_heading level0 col4\" >precision</th>\n",
       "      <th id=\"T_56b81_level0_col5\" class=\"col_heading level0 col5\" >recall</th>\n",
       "      <th id=\"T_56b81_level0_col6\" class=\"col_heading level0 col6\" >f1</th>\n",
       "      <th id=\"T_56b81_level0_col7\" class=\"col_heading level0 col7\" >loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56b81_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_56b81_row0_col0\" class=\"data row0 col0\" >abdbafc2361e489981e41636a3ea3b1a</td>\n",
       "      <td id=\"T_56b81_row0_col1\" class=\"data row0 col1\" >distilbert-base-uncased-lora-128-weighted_loss</td>\n",
       "      <td id=\"T_56b81_row0_col2\" class=\"data row0 col2\" >distilbert-base-uncased</td>\n",
       "      <td id=\"T_56b81_row0_col3\" class=\"data row0 col3\" >0.723100</td>\n",
       "      <td id=\"T_56b81_row0_col4\" class=\"data row0 col4\" >0.723700</td>\n",
       "      <td id=\"T_56b81_row0_col5\" class=\"data row0 col5\" >0.976300</td>\n",
       "      <td id=\"T_56b81_row0_col6\" class=\"data row0 col6\" >0.831200</td>\n",
       "      <td id=\"T_56b81_row0_col7\" class=\"data row0 col7\" >0.663600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56b81_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_56b81_row1_col0\" class=\"data row1 col0\" >255739eca4994d8f9c5e8bc0da3a0f8a</td>\n",
       "      <td id=\"T_56b81_row1_col1\" class=\"data row1 col1\" >distilbert-base-uncased-lora-128-weighted_loss</td>\n",
       "      <td id=\"T_56b81_row1_col2\" class=\"data row1 col2\" >distilbert-base-uncased</td>\n",
       "      <td id=\"T_56b81_row1_col3\" class=\"data row1 col3\" >0.723100</td>\n",
       "      <td id=\"T_56b81_row1_col4\" class=\"data row1 col4\" >0.723700</td>\n",
       "      <td id=\"T_56b81_row1_col5\" class=\"data row1 col5\" >0.976300</td>\n",
       "      <td id=\"T_56b81_row1_col6\" class=\"data row1 col6\" >0.831200</td>\n",
       "      <td id=\"T_56b81_row1_col7\" class=\"data row1 col7\" >0.663600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56b81_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_56b81_row2_col0\" class=\"data row2 col0\" >19480f2e08ff4011811d623a0759291b</td>\n",
       "      <td id=\"T_56b81_row2_col1\" class=\"data row2 col1\" >distilbert-base-uncased-lora-128-weighted_loss</td>\n",
       "      <td id=\"T_56b81_row2_col2\" class=\"data row2 col2\" >distilbert-base-uncased</td>\n",
       "      <td id=\"T_56b81_row2_col3\" class=\"data row2 col3\" >0.723100</td>\n",
       "      <td id=\"T_56b81_row2_col4\" class=\"data row2 col4\" >0.723700</td>\n",
       "      <td id=\"T_56b81_row2_col5\" class=\"data row2 col5\" >0.976300</td>\n",
       "      <td id=\"T_56b81_row2_col6\" class=\"data row2 col6\" >0.831200</td>\n",
       "      <td id=\"T_56b81_row2_col7\" class=\"data row2 col7\" >0.663600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56b81_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_56b81_row3_col0\" class=\"data row3 col0\" >12dcab98a908407eae2724292216703e</td>\n",
       "      <td id=\"T_56b81_row3_col1\" class=\"data row3 col1\" >distilbert-base-uncased-lora-128-weighted_loss</td>\n",
       "      <td id=\"T_56b81_row3_col2\" class=\"data row3 col2\" >distilbert-base-uncased</td>\n",
       "      <td id=\"T_56b81_row3_col3\" class=\"data row3 col3\" >0.698300</td>\n",
       "      <td id=\"T_56b81_row3_col4\" class=\"data row3 col4\" >0.720200</td>\n",
       "      <td id=\"T_56b81_row3_col5\" class=\"data row3 col5\" >0.929000</td>\n",
       "      <td id=\"T_56b81_row3_col6\" class=\"data row3 col6\" >0.811400</td>\n",
       "      <td id=\"T_56b81_row3_col7\" class=\"data row3 col7\" >0.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56b81_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_56b81_row4_col0\" class=\"data row4 col0\" >2e976997a8244ec5b4e998bc08d57ba9</td>\n",
       "      <td id=\"T_56b81_row4_col1\" class=\"data row4 col1\" >distilbert-base-uncased-lora-128-weighted_loss</td>\n",
       "      <td id=\"T_56b81_row4_col2\" class=\"data row4 col2\" >distilbert-base-uncased</td>\n",
       "      <td id=\"T_56b81_row4_col3\" class=\"data row4 col3\" >0.698300</td>\n",
       "      <td id=\"T_56b81_row4_col4\" class=\"data row4 col4\" >0.720200</td>\n",
       "      <td id=\"T_56b81_row4_col5\" class=\"data row4 col5\" >0.929000</td>\n",
       "      <td id=\"T_56b81_row4_col6\" class=\"data row4 col6\" >0.811400</td>\n",
       "      <td id=\"T_56b81_row4_col7\" class=\"data row4 col7\" >0.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56b81_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_56b81_row5_col0\" class=\"data row5 col0\" >a871100d092f49d887fbca4a0152e038</td>\n",
       "      <td id=\"T_56b81_row5_col1\" class=\"data row5 col1\" >distilbert-base-uncased-lora-128-weighted_loss</td>\n",
       "      <td id=\"T_56b81_row5_col2\" class=\"data row5 col2\" >distilbert-base-uncased</td>\n",
       "      <td id=\"T_56b81_row5_col3\" class=\"data row5 col3\" >0.698300</td>\n",
       "      <td id=\"T_56b81_row5_col4\" class=\"data row5 col4\" >0.720200</td>\n",
       "      <td id=\"T_56b81_row5_col5\" class=\"data row5 col5\" >0.929000</td>\n",
       "      <td id=\"T_56b81_row5_col6\" class=\"data row5 col6\" >0.811400</td>\n",
       "      <td id=\"T_56b81_row5_col7\" class=\"data row5 col7\" >0.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56b81_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_56b81_row6_col0\" class=\"data row6 col0\" >7c40f803f5ad446cb36321523e103ccd</td>\n",
       "      <td id=\"T_56b81_row6_col1\" class=\"data row6 col1\" >biobert-base-cased-v1.1-lora-128-weighted_loss</td>\n",
       "      <td id=\"T_56b81_row6_col2\" class=\"data row6 col2\" >biobert-base-cased-v1.1</td>\n",
       "      <td id=\"T_56b81_row6_col3\" class=\"data row6 col3\" >0.309900</td>\n",
       "      <td id=\"T_56b81_row6_col4\" class=\"data row6 col4\" >0.625000</td>\n",
       "      <td id=\"T_56b81_row6_col5\" class=\"data row6 col5\" >0.029600</td>\n",
       "      <td id=\"T_56b81_row6_col6\" class=\"data row6 col6\" >0.056500</td>\n",
       "      <td id=\"T_56b81_row6_col7\" class=\"data row6 col7\" >0.709200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8e56203410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare latest runs (table) with nicer formatting\n",
    "import glob, os, pandas as pd, numpy as np\n",
    "\n",
    "def _read_metrics(run_dir):\n",
    "    m = {}\n",
    "    for f in glob.glob(f'{run_dir}/metrics/test_*'):\n",
    "        with open(f) as fh:\n",
    "            t, v, step = fh.read().strip().split()\n",
    "            m[os.path.basename(f)] = float(v)\n",
    "    return m\n",
    "\n",
    "def _extract_model(run_name):\n",
    "    # Expect '<model>-lora-<maxlen>-<imbalance>'\n",
    "    if not run_name:\n",
    "        return None\n",
    "    parts = run_name.split('-lora-')[0]\n",
    "    return parts\n",
    "\n",
    "runs = sorted(glob.glob('results/mlruns/*/*'), key=os.path.getmtime)[-30:]\n",
    "rows = []\n",
    "for rd in runs:\n",
    "    m = _read_metrics(rd)\n",
    "    if not m:\n",
    "        continue\n",
    "    run_id = os.path.basename(rd)\n",
    "    run_name = None\n",
    "    tag = os.path.join(rd, 'tags', 'mlflow.runName')\n",
    "    if os.path.exists(tag):\n",
    "        run_name = open(tag).read().strip()\n",
    "    rows.append({\n",
    "        'run_id': run_id,\n",
    "        'run_name': run_name,\n",
    "        'model': _extract_model(run_name),\n",
    "        'accuracy': m.get('test_eval_accuracy') or m.get('test_accuracy'),\n",
    "        'precision': m.get('test_eval_precision') or m.get('test_precision'),\n",
    "        'recall': m.get('test_eval_recall') or m.get('test_recall'),\n",
    "        'f1': m.get('test_eval_f1') or m.get('test_f1'),\n",
    "        'loss': m.get('test_eval_loss') or m.get('test_loss'),\n",
    "    })\n",
    "\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Round numeric cols\n",
    "    num_cols = ['accuracy','precision','recall','f1','loss']\n",
    "    for col in num_cols:\n",
    "        if col in df:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').round(4)\n",
    "    sort_col = 'f1' if df['f1'].notna().any() else 'accuracy'\n",
    "    df = df.sort_values(by=sort_col, ascending=False, na_position='last').reset_index(drop=True)\n",
    "    try:\n",
    "        display(df.style.highlight_max(axis=0, subset=[sort_col], color='#d1ffd1'))\n",
    "    except Exception:\n",
    "        display(df)\n",
    "else:\n",
    "    print('No runs with test metrics found in results/mlruns.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
